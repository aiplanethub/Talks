{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Pre-processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM0D-N6CdZ_i",
        "colab_type": "text"
      },
      "source": [
        "**Author:** Manish KC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCkA86FMztFs",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Data Pre-processing\n",
        "Data pre-processing is one of the important step of the Data Science pipeline. The quality of data and the useful information can be derived from it which directly affects our model to learn. It is also necessary to convert the categorical data to numerical as machine learning algorithm takes only numerical data. In this tutorial, you will learn basic data pre-processing steps.\n",
        "\n",
        "### Agenda\n",
        "*  Loading Libraries\n",
        "*  Loading Data\n",
        "*  Data Overview and Summary\n",
        "*  Data Pre-processing\n",
        "    *  Dropping Irrelavent Features\n",
        "    *  Dropping Rows with Missing Values\n",
        "    *  Problems with dropping rows\n",
        "    *  Taking care of missing data\n",
        "    *  Handling Categorical Variables - Creating Dummy Variables\n",
        "    * Separating input variables and output variable\n",
        "    * Splitting the data into train set and test set\n",
        "\n",
        "We are going to use the titanic dataset.\n",
        "\n",
        "## About Titanic\n",
        "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
        "\n",
        "In the Hollywood blockbuster that was modelled on this tragedy, it seemed to be the case that upper-class people, women and children were more likely to survive than others. But did these properties (socio-economic status, sex and age) really influence one's survival chances?\n",
        "\n",
        "#### **Problem Identification: The goal is to predict who survived during this titanic incident (shipwreck).**\n",
        "\n",
        "#### Dataset download link\n",
        "https://docs.google.com/spreadsheets/d/1hFOPnxVT9fyT4TFlwuGGbDLfclY43P48UV24PNfAW2M/edit#gid=1297342310"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5H5ZLLN4P7e",
        "colab_type": "text"
      },
      "source": [
        "## Loading Libraries\n",
        "You can load all the libraries that you think will require or you can import as you go along.\n",
        "\n",
        "**Alias for libraries:** numpy --> np, pandas --> pd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz9HzzhSzm9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np        # A fundamental package for linear algebra and multidimensional arrays\n",
        "import pandas as pd       # Data analysis and manipulation tool."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NewOrBew5xBT",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data\n",
        "The data is in csv format. Let's load the csv data using pandas read_csv() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP7GfKaM48XX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I have provided the path of data which I have saved in my drive as 'titanic_train_data'.\n",
        "# You provide the path where you have saved the data.\n",
        "titanic_data = pd.read_csv(\"/content/drive/My Drive/Datasets/titanic_train_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiEmdMWh7wBY",
        "colab_type": "text"
      },
      "source": [
        "## Data Overview and Summary\n",
        "Let's look how the data look like and a concise summary of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYrp9_Ju7kEC",
        "colab_type": "code",
        "outputId": "08914861-5459-422d-ad36-932fa41533f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Displaying 5 random records\n",
        "titanic_data.sample(5)     # You can pass the number of random records that you want to be displayed in 'sample()'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>536</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Hart, Miss. Eva Miriam</td>\n",
              "      <td>female</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>F.C.C. 13529</td>\n",
              "      <td>26.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>634</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Parr, Mr. William Henry Marsh</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112052</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>553</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>O'Brien, Mr. Timothy</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330979</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>490</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Coutts, Master. Eden Leslie \"Neville\"</td>\n",
              "      <td>male</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>C.A. 37671</td>\n",
              "      <td>15.9000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>571</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Harris, Mr. George</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S.W./PP 752</td>\n",
              "      <td>10.5000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "535          536         1       2  ...  26.2500   NaN         S\n",
              "633          634         0       1  ...   0.0000   NaN         S\n",
              "552          553         0       3  ...   7.8292   NaN         Q\n",
              "489          490         1       3  ...  15.9000   NaN         S\n",
              "570          571         1       2  ...  10.5000   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJR0CeoZ8fm1",
        "colab_type": "text"
      },
      "source": [
        "We can observe that there are some null values (i.e. NaN) in 'Age' and 'Cabin' attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZAybhLZ8ZfP",
        "colab_type": "code",
        "outputId": "cfcd8327-150d-4a26-d522-0c36bdb5c637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# A concise summary of the data\n",
        "titanic_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_h1fsWD863h",
        "colab_type": "text"
      },
      "source": [
        "The concise summary of data tells us:\n",
        "*  There are total 891 observations / records in the dataset\n",
        "*  Age, Cabin and Embarked features have missing values. Cabin has a lot of missing values. Embarked has only two missing values.\n",
        "*  There are some categorical variables like Embarked, Sex, which are required to be converted into numerical.\n",
        "\n",
        "Similarly, you can observe some other information from above concise summary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuqUvxEeV-0x",
        "colab_type": "text"
      },
      "source": [
        "#### Exploring the attributes:\n",
        "*  'Pclass' column contains a number which indicates class of the passenger's ticket:  1 for first class, 2 for second class and 3 for third class. This could function as a proxy for the socio-economic status of the passenger ('upper', 'middle', 'low'). \n",
        "\n",
        "\n",
        "*  The 'SibSp' column contains the number of siblings + spouses of the passenger also aboard the Titanic;\n",
        "\n",
        "*  The 'ParCh' column indicates the number of parents + children of the passenger also aboard the Titanic. \n",
        "\n",
        "*  The 'Ticket' column contains the ticket numbers of passengers (which are not likely to have any predictive power regarding survival);\n",
        "\n",
        "*  'Cabin' contains the cabin number of the passenger, if he/she had a cabin, and lastly, \n",
        "\n",
        "*  'Embarked' indicates the port of embarkation of the passenger: **C**herbourg, **Q**ueenstown or **S**outhampton. The meaning of the other columns is clear, I think."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nckRIyKk9jnj",
        "colab_type": "text"
      },
      "source": [
        "# Data Pre - processing\n",
        "Now we come to the main agenda of this tutorial i.e. data pre-processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vmc5-Ed-bIs",
        "colab_type": "text"
      },
      "source": [
        "### Dropping Irrelavent Features / Columns\n",
        "Here the goal is to predict the survival of the passengers. We can understand form our common sense or understanding that a person cannot survive because of his / her name, ticket number or cabin. So, we can say that these are irrelavent features. Let's drop these features from the dataset as these do not contribute much for the survival of the passenger.\n",
        "\n",
        "This is very subjective and solely depends on the nature of the dataset and underlying context. We cannot generalize this procedure to all the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9O9IBso80A2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols_to_drop = ['Name', 'Ticket', 'Cabin']     # columns / features to be dropped\n",
        "\n",
        "# We can use .drop() frunction of pandas to drop the columns. If you remember from the pandas session, for columns to be dropped the axis must be 1.\n",
        "titanic_data.drop(columns = cols_to_drop, axis = 1, inplace = True)     # we are making changes in the dataframe itself, so, inplace = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52o0s9MoBRQK",
        "colab_type": "code",
        "outputId": "24c0122a-3b65-4e21-de03-ce136961c773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Let's check what columns we have using 'columns' method\n",
        "titanic_data.columns                   # returns list of columns in the dataframe"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
              "       'Fare', 'Embarked'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL6fwyVgBg5n",
        "colab_type": "text"
      },
      "source": [
        "If you notice, there are no 'Name', 'Ticket' and 'Cabin' features in the dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV7MrMXqBs6N",
        "colab_type": "text"
      },
      "source": [
        "### Dropping Rows with Missing Values\n",
        "We can also drop some rows with missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk6Lv5TEBewE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First let's make a copy of the dataset\n",
        "data = titanic_data.copy()        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Sy31UgCEp9",
        "colab_type": "text"
      },
      "source": [
        "Now, we will drop rows with missing values from 'data'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsWXV3o1CCf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Again the drop() function of pandas can be used to drop rows with missing values. The only change will be axis = 0 instead of axis = 1\n",
        "data.dropna(axis = 0, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERkstxdyETgB",
        "colab_type": "code",
        "outputId": "e3d3e9bf-2a4e-43bb-ccf5-bc86a820ff8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# looking at the info\n",
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 712 entries, 0 to 890\n",
            "Data columns (total 9 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  712 non-null    int64  \n",
            " 1   Survived     712 non-null    int64  \n",
            " 2   Pclass       712 non-null    int64  \n",
            " 3   Sex          712 non-null    object \n",
            " 4   Age          712 non-null    float64\n",
            " 5   SibSp        712 non-null    int64  \n",
            " 6   Parch        712 non-null    int64  \n",
            " 7   Fare         712 non-null    float64\n",
            " 8   Embarked     712 non-null    object \n",
            "dtypes: float64(2), int64(5), object(2)\n",
            "memory usage: 55.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvUbA8qeEjb1",
        "colab_type": "text"
      },
      "source": [
        "### Problems with droping rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze4Bdn8BEXxw",
        "colab_type": "code",
        "outputId": "5e79cd7c-00d4-49e2-bc42-104c7a9f26c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Number of rows dropped\n",
        "891- 712"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGssO80-EgOb",
        "colab_type": "text"
      },
      "source": [
        "If you notice here we have dropped 179 rows out of 891 rows and have lost lot of data i.e. out of 891 records, 179 records are good amount of data and we have lost those data.\n",
        "\n",
        "The more data you feed the machine learning model, the better performance it gives. So, we always try to preserve data as much as possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1tufjWpEc4d",
        "colab_type": "code",
        "outputId": "7d391a12-9028-4d1d-a26b-cb678b3c1427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# We have our titanic_data where we have not removed any rows.\n",
        "titanic_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 9 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Sex          891 non-null    object \n",
            " 4   Age          714 non-null    float64\n",
            " 5   SibSp        891 non-null    int64  \n",
            " 6   Parch        891 non-null    int64  \n",
            " 7   Fare         891 non-null    float64\n",
            " 8   Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(2)\n",
            "memory usage: 62.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_7Sip14Glrl",
        "colab_type": "text"
      },
      "source": [
        "### Taking Care of Missing Data\n",
        "There are some missing values in 'Age' and 'Embarked' features.\n",
        "\n",
        "We can compute median or interpolate() to fill the missing values of 'Age' feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMTMhQIOGczp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titanic_data['Age'] = titanic_data['Age'].interpolate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj_MSQ-3LAaZ",
        "colab_type": "text"
      },
      "source": [
        "'Embarked' is a categorical variable. Let's take a look at its unique values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdC6mMn9IkiW",
        "colab_type": "code",
        "outputId": "884827a1-df11-4c7f-a6e2-51ae1d7f25a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "titanic_data.Embarked.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['S', 'C', 'Q', nan], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeQzAmdmLNZt",
        "colab_type": "text"
      },
      "source": [
        "There are 3 unique values with two missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kGGvbhXLKQJ",
        "colab_type": "code",
        "outputId": "d6efeca3-c53c-412b-aca5-fb8e8ce97ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Looking at frequency of each values in 'Embarked'\n",
        "titanic_data.Embarked.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "S    644\n",
              "C    168\n",
              "Q     77\n",
              "Name: Embarked, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "netEJSzjLhft",
        "colab_type": "text"
      },
      "source": [
        "'S' is the most occuring value in 'Embarked' column. So, we can fill the two missing values with 'S' assuming that the two passengers whose port of Embarkation is missing might have embarked from 'Southampton' i.e. 'S'.\n",
        "\n",
        "Let's fill the null values of Embarked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEqseBNELgAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can use fillna() function to fill the missing values as discussed in the pandas session / notebook.\n",
        "titanic_data.Embarked.fillna(value='S', axis = 0, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXRpe8fQMyND",
        "colab_type": "code",
        "outputId": "ea24d7c2-560c-4092-ae4e-df9c52b4872b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# We can check if there still exist any missing value using the info() method\n",
        "titanic_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 9 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Sex          891 non-null    object \n",
            " 4   Age          891 non-null    float64\n",
            " 5   SibSp        891 non-null    int64  \n",
            " 6   Parch        891 non-null    int64  \n",
            " 7   Fare         891 non-null    float64\n",
            " 8   Embarked     891 non-null    object \n",
            "dtypes: float64(2), int64(5), object(2)\n",
            "memory usage: 62.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4S0syE1NHsF",
        "colab_type": "text"
      },
      "source": [
        "All the features have 891 non - null values. Now we don't have nay missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_Q7PjzCNaJr",
        "colab_type": "text"
      },
      "source": [
        "### Handling Categorical Variables - Creating Dummy Variables\n",
        "There are many methods of dealing with categorical data. One of the known method is creating dummy variables.\n",
        "\n",
        "**Creating Dummy Variables:**\n",
        "Let's understand using Embarked feature. This feature has 3 unique values. \n",
        "In this case 3 new features will be created - 'C', 'Q' and 'S'. If the passenger had embarked from 'Cherbourg' (i.e. C), the newly generated column 'C' will have its value as 1 else 0 and similarly for other dummy variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtmJrGQ3TdgH",
        "colab_type": "text"
      },
      "source": [
        "There are three categorical feature with us in this dataset - Pclaa, Sex and Embarked. Let's create dummy variables for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBIVoxfaNFUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titanic_data = pd.get_dummies(titanic_data, columns=['Pclass', 'Sex', 'Embarked'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsIyl7dGUtrn",
        "colab_type": "code",
        "outputId": "c8b7e18a-487c-46c4-88dc-0cd69639281a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "titanic_data.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived   Age  ...  Embarked_C  Embarked_Q  Embarked_S\n",
              "0            1         0  22.0  ...           0           0           1\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFpjLSJHVRgp",
        "colab_type": "text"
      },
      "source": [
        "The columns: Pclass_1, Pclass_2, Pclass_3, Sex_female, Sex_male, Embarked_C, Embarked_Q and Embarked_S are our dummy variables. The original columns are dropped by itself from the dataframe. If we had created dummhy variables separately for each column and then concatenated all those variables to the datafram then we had needed to drop those parent columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaeUqGDsXObz",
        "colab_type": "text"
      },
      "source": [
        "### Separating Target and Input Features\n",
        "We feed the data to the algorithms as the input features (i.e. independent variables) and the target feature (i.e. dependent variable). So, we separate these features form the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz6DgGyPUvRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = titanic_data.drop(columns=['Survived'])     # these are independent features. The change of dropping the column 'Survived' is not inplace.\n",
        "\n",
        "Y = titanic_data.Survived               # The target feature or dependent feature."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trmrdc7XYY8K",
        "colab_type": "text"
      },
      "source": [
        "### Splitting data into Train set and Test set\n",
        "The test set of the data is used to check how the built model is performing.\n",
        "Generally, people use 70% of the data for trainig the model and 30% for testing the model. Some people also use the ratio as 80% or 90% for training and 20% or 10%  for testing.\n",
        "\n",
        "The splitting is done using train_test_split class from sklearn.model selection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYXiNVTwYSzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the class\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)\n",
        "\n",
        "# X_train: independent feature data for training the model\n",
        "# Y_train: dependent feature data for training the model\n",
        "# X_test: independent feature data for testing the model; will be used to predict the target values\n",
        "# Y_test: original target values of X_test; We will compare this values with our predicted values.\n",
        " \n",
        "# test_size = 0.30: 30% of the data will go for test set and 70% of the data will go for train set\n",
        "# random_state = 42: this will fix the split i.e. there will be same split for each time you run the code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhlPghgXalRk",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "That's it in this tutorial about Data Pre - processing. Here we discussed some basic stuff about data pre - processing. Later we will learn stuffs like standardization, normalization, One Hot Encoding, etc. in data pre - processing.\n",
        "Thanks!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxa4WdfybUzi",
        "colab_type": "text"
      },
      "source": [
        "#### **References:**\n",
        "1. [Implementation of Data Preprocessing on Titanic Dataset by Afroz Chakure](https://towardsdatascience.com/implementation-of-data-preprocessing-on-titanic-dataset-6c553bef0bc6)\n",
        "2. [Data Pre-Processing By Ayon Roy at DPhi](https://www.youtube.com/watch?v=ni5BO0mO1x8)\n",
        "3. [Introduction to Data Preprocessing in Machine Learning by Dhairya Kumar](https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d#:~:text=Data%20preprocessing%20is%20an%20integral,feeding%20it%20into%20our%20model.)"
      ]
    }
  ]
}